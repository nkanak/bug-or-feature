{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import contractions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import numpy as np\n",
    "import fasttext\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import norm\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import SGConv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import shap\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "# Set fixed random number seed\n",
    "#torch.manual_seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_precision_recall(true_labels, predicted_labels):\n",
    "    return (accuracy_score(true_labels, predicted_labels),\n",
    "           precision_score(true_labels, predicted_labels),\n",
    "           recall_score(true_labels, predicted_labels))\n",
    "\n",
    "def print_evaluation_results(results):\n",
    "    print('Avg accuracy | Avg precision | Avg recall')\n",
    "    avg_accuracy, avg_precision, avg_recall = np.mean(results, axis=0)\n",
    "    std_accuracy, std_precision, std_recall = np.std(results, axis=0)\n",
    "    print(f'{avg_accuracy:.4f}+-{std_accuracy:.4f}, {avg_precision:.4f}+-{std_precision:.4f}, {avg_recall:.4f}+-{std_recall:.4f}')\n",
    "\n",
    "def get_random_number():\n",
    "    return random.randint(0, 10000)\n",
    "\n",
    "global_random_number = get_random_number()\n",
    "global_random_numbers = [get_random_number() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407799"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('samples.csv')\n",
    "# bug == 0 and feature == 1\n",
    "df = df[(df['label'] == 0) | (df['label'] == 1)]\n",
    "#df = df[:500]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.add('__label__', 'REMOVED_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix contractions\n",
    "df['title'] = df['title'].apply(contractions.fix)\n",
    "df['body'] = df['body'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of stopwords\n",
    "df['title'] = df['title'].apply(remove_stopwords)\n",
    "df['body'] = df['body'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_words_of_title'] = df['title'].str.split().str.len()\n",
    "df['number_of_words_of_body'] = df['body'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['number_of_words_of_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    407799.000000\n",
       "mean          4.966165\n",
       "std           2.007483\n",
       "min           0.000000\n",
       "25%           3.000000\n",
       "50%           5.000000\n",
       "75%           6.000000\n",
       "max          43.000000\n",
       "Name: number_of_words_of_title, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of words of title')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.histplot(data=df, x='number_of_words_of_title', kde=False, stat='count', binwidth=1)\n",
    "fig.set_xlabel('Number of words of title')\n",
    "#fig.get_figure().savefig('figures/price_kde_histogram.jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of words of body')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.histplot(data=df, x='number_of_words_of_body', kde=False, stat='count', binwidth=15)\n",
    "fig.set_xlabel('Number of words of body')\n",
    "#fig.get_figure().savefig('figures/price_kde_histogram.jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    407799.000000\n",
       "mean          4.966165\n",
       "std           2.007483\n",
       "min           0.000000\n",
       "25%           3.000000\n",
       "50%           5.000000\n",
       "75%           6.000000\n",
       "max          43.000000\n",
       "Name: number_of_words_of_title, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['number_of_words_of_title'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    407799.000000\n",
       "mean         45.938685\n",
       "std          63.545595\n",
       "min           0.000000\n",
       "25%          12.000000\n",
       "50%          24.000000\n",
       "75%          52.000000\n",
       "max         977.000000\n",
       "Name: number_of_words_of_body, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['number_of_words_of_body'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    207318\n",
       "0    200481\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bugs == 0\n",
    "# feature == 1\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 273225\n",
      "Test size 134574\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = train_test_split(df.body, test_size=0.33, random_state=42)\n",
    "print('Train size', len(x_train))\n",
    "print('Test size', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.histplot(data=df[df['number_of_words_of_title'] < 15], x='number_of_words_of_title', kde=False, stat='count', binwidth=1)\n",
    "fig.set_xlabel('number of words of title')\n",
    "fig.get_figure().savefig('figures/number_of_words_of_title_less_than_15.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEJCAYAAABR4cpEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcn0lEQVR4nO3df7hdVXng8e+9yRXySEIgXIYgQpuH8sJoTRwFrYCgom1EEUeBEQpmpoAIWJ5OpbU1KT+KdBwcFK0o5UdhDAIVHEeFtGi0EOWHIoIVyltGIQqEEoMSovy4l5v5Y69DDpebe06y77n3nOT7eZ48nLPO2uu8ex/uec9aa++1+9avX48kSXX0T3UAkqTeZzKRJNVmMpEk1WYykSTVZjKRJNU2faoDmALbAPsCq4DnpjgWSeoV04C5wPeBZ0a/uDUmk32BFVMdhCT1qAOB74wu3BqTySqAX/7y14yMbN41NnPmbMeaNesmNKhOMM6J1StxQu/EapwTq5Nx9vf3scMOL4XyHTra1phMngMYGVm/2cmksX0vMM6J1StxQu/EapwTaxLiHHN6wAl4SVJtHe2ZRMS3gZ2BoVL0AWAmcD4wA7gmMxeXuguAS4BZwM3ASZk5HBG7A0tLOwkck5nrImI2cCUwD1gNHJmZj3ZyfyRJY+tYzyQi+oC9gPmZuSAzFwA/Ai4D3gXsA+wbEQvLJkuBUzNzL6APOKGUXwhcmJl7A3cAS0r5OcCKzNwHuBi4oFP7IkkaXyeHuaL898aIuDsiTgX2A+7PzAcyc5gqgRwREXsAMzLztrLN5aV8AHgjcG1zeXl8KFXPBOAqYGGpL0maZJ0c5toBWA58CBgA/hn4OC88E2AVsBuw60bKdwLWlsTTXE7zNmU4bC0wCDzSTnBz5my3yTvUbHBwZq3tJ4txTqxeiRN6J1bjnFhTFWfHkklm3grc2ngeEZcCZ/PC85P7gBGqHtL6Nsop5Y06zfqaXmtpzZp1m33Ww+DgTFavfnKztp1MxjmxeiVO6J1YjXNidTLO/v6+cX+Ed3LO5ICIeEtTUR/wINUVlA27UPUkHtpI+WPA9hExrZTPZUPP4+FSj4iYTjWxv2Zi90KS1I5ODnPNBs6OiDdQDXO9HzgJ+IeI2BN4ADgauCwzV0bE0xGxf2Z+FzgWWJaZQxGxAjgK+CJwHLCstH9DeX5ueX1FZg6xlZi1/Qy2eUnrj2+8Lu8zzw6z9omnJjIsSVupTg5zfT0iXgf8kGpNl89m5q0RsQi4DtiWKiE0JtePAS6OiFnAncCnS/nJwBURsRj4GfC+Ur4EuDwi7gF+VbbfamzzkumcfsFN49YZGJjO0NDwRl8/77SDJjosSVupjl5nkplL2HAqb6NsOTB/jLp3U53tNbp8JXDwGOWPA4dNVKySpM3nFfCSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2jq6BL3G1u6NrSSpV/iNNgXaubFVK97YSlI3cZhLklSbyUSSVJvJRJJUm8lEklSbyUSSVJvJRJJUm8lEklSbyUSSVJvJRJJUm8lEklSbyUSSVJvJRJJUm8lEklSbyUSSVJvJRJJUm8lEklSbyUSSVFvH77QYEZ8AdsrMRRFxCHA+MAO4JjMXlzoLgEuAWcDNwEmZORwRuwNLgZ2BBI7JzHURMRu4EpgHrAaOzMxHO70vW5qh4REGB2fWauOZZ4dZ+8RTExSRpF7V0WQSEW8B3g9cHxEzgMuAg4Cfl7KFmbmMKmEcn5m3RcSlwAnA54ALgQsz8+qIWAIsAf4cOAdYkZmHRsSxwAXAUZ3cly3RwPR+bx8saUJ0bJgrInYEPgacW4r2A+7PzAcyc5gqgRwREXsAMzLztlLv8lI+ALwRuLa5vDw+lKpnAnAVsLDUlyRNgU72TC4CPgq8vDzfFVjV9PoqYLdxyncC1pbE01z+grbKcNhaYBB4pN3g5szZblP25UXqDg8NDNQ/9O200arORMRR91hMVBuToVfihN6J1Tgn1lTF2ZFkEhHHAz/PzOURsagU9wPrm6r1ASObUE4pb9Rp1tf0WlvWrFnHyMjo5tszODiT1auf3KxtG9sPDQ23rthCqzYGBqa3rDMRcdQ5FlD/eE6WXokTeidW45xYnYyzv79v3B/hneqZHAXMjYi7gB2B7YA9gOea6uxC1ZN4CJg7RvljwPYRMS0znyt1Gj2Ph0u9hyJiOjATWNOhfZEktdCROZPMfGtmvjIzFwB/BXwVWAhEROwZEdOAo4FlmbkSeDoi9i+bH1vKh4AVbJhYPw5YVh7fUJ5TXl9R6kuSpsCkXWeSmU8Di4DrgHuB+9gwuX4M8MmIuI+qF/PpUn4ycGJE3AscCCwu5UuA10fEPaXOKZOxD5KksXX8OpPMvJzqTCwyczkwf4w6d1Od7TW6fCVw8BjljwOHTWykkqTN5RXwkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2qZPdQDqbUPDIwwOzqzdhqTeZjJRLQPT+zn9gptqtXHeaQdNUDSSporDXJKk2kwmkqTaTCaSpNpMJpKk2kwmkqTaTCaSpNpMJpKk2jp6nUlEnA28F1gPXJqZ50fEIcD5wAzgmsxcXOouAC4BZgE3Aydl5nBE7A4sBXYGEjgmM9dFxGzgSmAesBo4MjMf7eT+SJLG1rGeSUQcBLwZeBXwWuBDETEfuAx4F7APsG9ELCybLAVOzcy9gD7ghFJ+IXBhZu4N3AEsKeXnACsycx/gYuCCTu2LJGl8HUsmmXkT8KbMHKbqVUwHZgP3Z+YDpXwpcERE7AHMyMzbyuaXl/IB4I3Atc3l5fGhVD0TgKuAhaW+JGmSdXSYKzOHIuIs4MPAl4BdgVVNVVYBu41TvhOwtiSe5nKatynDYWuBQeCRdmKbM2e7zdml59Vdj2pgoP6hb6eNVnUmK45W6h7PydIrcULvxGqcE2uq4uz42lyZeUZEfBz4GrAX1fxJQx8wQtVDaqecUt6o06yv6bWW1qxZx8jI6KbbMzg4k9Wrn9ysbRvbDw0Nt67YQqs2Bgamt6wzGXG0o87xnCx1P/fJ1CuxGufE6mSc/f194/4I7+Scyd5lUp3M/A3wZeBgYG5TtV2oehIPbaT8MWD7iJhWyueyoefxcKlHREwHZgJrOrArkqQWOnlq8Dzg4ojYJiJeQjXpfhEQEbFnSRBHA8sycyXwdETsX7Y9tpQPASuAo0r5ccCy8viG8pzy+opSX5I0ydpKJhFx6Rhl145VtyEzbwCuB34I/AC4JTOvBhYB1wH3AvexYXL9GOCTEXEfsB3w6VJ+MnBiRNwLHAgsLuVLgNdHxD2lzint7IskaeKNO2cSEZ8DXgYcGBGDTS8NUPU8xpWZZwJnjipbDswfo+7dwH5jlK+kGh4bXf44cFirGCRJnddqAv5S4JVUX/7XNZUPA7eNuYUkaaszbjLJzDuAOyLim5n50CTFJEnqMe2eGvzyiPgCsCNNp+Rm5qs6EpUkqae0m0wuorr6/E5efN2HJGkr124yGc7M8zsaiSSpZ7V7ncmPI+J3OxqJJKlntdszmQf8ICJWAk81Cp0zkSRB+8nkox2NQlu1oeGR2ovTPfPsMGufeKp1RUkd0W4y+ZeORqGt2sD0fk6/4KZabZx32kETFI2kzdFuMvkF1VlcfWw4m6t5OXhJ0lasrWSSmc9P1JdFG48GolNBSZJ6yyavGpyZz2bm5cBbJz4cSVIvaqtnEhE7Nj3to7qn+w4diUiS1HM2Z84EqptW/XFHIpIk9ZxNnjORJGm0doe5+oEPAwup7mVyI3BuZta/+bckqee12+P4G+DNwAXA+cAbgPM6FZQkqbe0O2fyB8BrG/dYj4jrgbuBP+lUYJKk3tFuz6S/kUgAMvMZYGic+pKkrUi7PZO7IuKTwN9SndX1IeBHHYtKktRT2u2ZnEJ1XcktwO3ATlQJRZKk8XsmZemUi4GvZOaiUnY98BywtuPRSZJ6QqueydnALOC7TWUnALOBMzsTkiSp17RKJu8Ajs7MxxoFmfkIcBzw7k4GJknqHa0m4J/NzBfdcSgz10bEMx2KSdpk3mBLmlqtkslzETEzM59sLoyImVRXwktdwRtsSVOr1TDXVcAlEfHSRkF5fAlwXScDkyT1jlY9k08BnwcejYh7qJLPPsCVVJPzkiSNn0wycwQ4MSI+BrwGGAFuz8xVkxGcJKk3tLsE/UpgZYdjkST1KO9TIkmqzWQiSarNZCJJqq3dVYM3S0ScARxZnl6fmX8WEYdQ3WBrBnBNZi4udRdQnXI8C7gZOCkzhyNid2ApsDOQwDGZuS4iZlOdVTYPWA0cmZmPdnJ/JElj61jPpCSNtwGvBhYAr4mI9wGXAe+iOsV434hYWDZZCpyamXsBfVRrgAFcCFyYmXsDdwBLSvk5wIrM3IdqMcoLOrUvkqTxdXKYaxXwp5n5bLmx1r8CewH3Z+YD5f7xS4EjImIPYEZm3la2vbyUDwBvBK5tLi+PD6XqmUB1ceXCUl+SNMk6NsyVmfc0HkfE71ANd32GKsk0rAJ2A3bdSPlOwNqSeJrLad6mDIetBQaBR9qJb86c7TZxj16o7jpQAwP1D307bbSqM1lx9EobrT7Xup/7ZOqVWI1zYk1VnB2dMwGIiFcA1wOnA8NUvZOGPqoLIfup7uDYqpxS3qjTrK/ptZbWrFnHyMjoptszODiT1aufbF1xnO2HhoZbV2yhVRsDA9Nb1pmMOHqpjfE+17qf+2TqlViNc2J1Ms7+/r5xf4R39GyuiNgfWA58JDOvAB4C5jZV2YWqJ7Gx8seA7SNiWimfy4aex8OlHhExHZgJrOnMnkiSxtPJCfiXA1+huh/K1aX49uql2LMkiKOBZeUK+6dL8gE4tpQPASuAo0r5ccCy8viG8pzy+opSX5I0yTo5zPVhYFvg/IholH0eWES14vC2VAmhMbl+DHBxRMwC7gQ+XcpPBq6IiMXAz4D3lfIlwOVlAcpfle2lzdbOPVFave49UbS16uQE/GnAaRt5ef4Y9e8G9hujfCVw8BjljwOH1YtS2qDVPVHamYPynijaWnkFvCSpNpOJJKk2k4kkqTaTiSSpNpOJJKk2k4kkqTaTiSSpNpOJJKk2k4kkqTaTiSSpto4vQS9tTdpZ36sV1/dSLzKZSBOo1fpe7XB9L/Uih7kkSbWZTCRJtZlMJEm1mUwkSbWZTCRJtZlMJEm1mUwkSbV5nYnUZSbiwseh4ZEJikZqj8lE6jJe+Khe5DCXJKk2k4kkqTaTiSSpNpOJJKk2k4kkqTaTiSSpNpOJJKk2k4kkqTYvWpS2QN4+WJPNZCJtgbyKXpPNYS5JUm0mE0lSbR0d5oqIWcAtwDsy88GIOAQ4H5gBXJOZi0u9BcAlwCzgZuCkzByOiN2BpcDOQALHZOa6iJgNXAnMA1YDR2bmo53cF0nSxnWsZxIRrwO+A+xVns8ALgPeBewD7BsRC0v1pcCpmbkX0AecUMovBC7MzL2BO4AlpfwcYEVm7gNcDFzQqf2QJLXWyZ7JCcApwBfK8/2A+zPzAYCIWAocERH3AjMy87ZS73LgrIi4BHgjcHhT+U3AnwOHltcArgI+GxEDmTnUwf2Rtip1zwjzbLCtS8eSSWYeDxARjaJdgVVNVVYBu41TvhOwNjOHR5W/oK0yHLYWGAQeaTe+OXO224S9ebG6p10ODNQ/9O200arOZMWxpbQxEcd8IuKYjDYGpvfzlxd+d7O3P/fk/dv6O6n7tzRZjHN8k3lqcD+wvul5HzCyCeWU8kadZn1Nr7VlzZp1jIyMbr49g4MzWb36yc3atrH90NBw64ottGpjYGB6yzqTEceW0kY7x3My4uilNlr9ndT9W5osxgn9/X3j/gifzLO5HgLmNj3fhaonsbHyx4DtI2JaKZ/Lhp7Hw6UeETEdmAms6VjkkqRxTWYyuR2IiNizJIijgWWZuRJ4OiL2L/WOLeVDwArgqFJ+HLCsPL6hPKe8vsL5EkmaOpM2zJWZT0fEIuA6YFuqhHBtefkY4OJyKvGdwKdL+cnAFRGxGPgZ8L5SvgS4PCLuAX5VtpfURdqdwB+vjpP4vaPjySQzf6vp8XJg/hh17qY622t0+Urg4DHKHwcOm8g4JU2sdpZ0aTUP5ZIuvcMr4CVJtZlMJEm1uWqwpK7lUvq9w2QiqWu5lH7vcJhLklSbyUSSVJvDXJK2aBMx7zI0vEmrNW2VTCaStmjOu0wOh7kkSbXZM5GkFjxFuTWTiSS14FBZaw5zSZJqs2ciSZNgSx8qM5lI0iTY0ofKHOaSJNVmMpEk1eYw12aYiLFPSdqSmEw2Q92xz24e95SkzeEwlySpNpOJJKk2k4kkqTaTiSSpNpOJJKk2k4kkqTaTiSSpNq8zkaQe0c4F061e79RikSYTSeoRrS6YHhiYztDQ8LhtdOqiaYe5JEm1mUwkSbWZTCRJtZlMJEm1mUwkSbWZTCRJtfX0qcERcTSwGBgAPpWZn53ikCRpq9SzPZOIeBnwMeAAYAFwYkT8xykNSpK2Ur3cMzkE+FZmPg4QEdcC7wXObrHdNID+/r5ab77DzG2mdPt22pg+MJ3hoWlTHseW0kY7x3My4uilNvx/dHLbaPf/0c35/mvaZsw36Fu/fv0mN9oNIuIvgJdm5uLy/Hhgv8w8scWmBwArOh2fJG2hDgS+M7qwl3sm/UBzJuwDRtrY7vtUB2MV8FwH4pKkLdE0YC7Vd+iL9HIyeYgqKTTsAjzSxnbPMEZWlSS19JONvdDLyeSbwJkRMQj8GngP0GqIS5LUAT17NldmPgx8FPg2cBfwxcz83pQGJUlbqZ6dgJckdY+e7ZlIkrqHyUSSVJvJRJJUm8lEklRbL58aPOm6fWHJiJgF3AK8IzMfjIhDgPOBGcA1jdUCplJEnAEcWZ5en5l/1o1xAkTE2VRL9KwHLs3M87s1VoCI+ASwU2Yu6sY4I+LbwM7AUCn6ADCT7ovzncAZwEuBGzPztC49nscDpzYV/TbwBeArTEGsns3VprKw5HeA11Bd+HgL8L7MvHdKAysi4nXAxcDewF7AvwMJHAT8HLieKgEum8IYDwHOAt5E9QX9j8AlwMe7KU6AiDiIaiHRg6l+PNwLHA58jS6LFSAi3gJcTRXTB+m+z76P6kLjPTJzuJTN6MI451Ett/Q6qr+hbwHnAhd1U5yjRcQrqJLIm4HvMgWxOszVvucXlszMXwONhSW7xQnAKWxYBWA/4P7MfKD88S4Fjpiq4IpVwJ9m5rOZOQT8K1Xi67Y4ycybgDeVmHam6sXPpgtjjYgdqRLfuaWoGz/7KP+9MSLujohT6c443031a/6h8v/oUcBv6L44R/sc8JfAPKYoVpNJ+3al+jJsWAXsNkWxvEhmHp+ZzQtYdl28mXlPZt4GEBG/QzXcNUKXxdmQmUMRcRZVr2Q5XXhMi4uoLuD9ZXnejXHuQHUM3w28BTgJ2J3ui3NPYFpEfDUi7gJOpjuP5/NKj39GZn6JKYzVZNK+zV1Ycqp0bbylS/4N4HTgp3RpnACZeQYwCLycqhfVVbGWcfOfZ+bypuKu++wz89bMPC4zn8jMXwCXUt0uoqvipOqBHgL8EfB7VMNd8+i+OJt9gGqOBKbwszeZtO8hqhUzG9pdWHKqdGW8EbE/1S/Uj2TmFXRvnHtHxAKAzPwN8GWq+ZNui/Uo4G3lV/TZwGHA8XRZnBFxQJnXaegDHqTL4gQeBb6Zmasz8yng/1All26LE4CIeAnV/MhXS9GU/T15Nlf7em1hyduBiIg9gQeAo4HLpjKgiHg51SThUZn5rVLcdXEW84CzIuIAql9676IaTjqvm2LNzLc2HkfEIqqEdxJwfzfFSTXfdHZEvIHqhIb3U8X5D10W59eBKyJiNvAksJBqfvQjXRZnw6uAfyvzuDCFf0/2TNrUawtLZubTwCLgOqox//uo/iim0oeBbYHzI+Ku8mt6Ed0XJ5l5A9WZMD8EfgDckplX04WxjtaNn31mfp0XHs/LMvNWui/O24H/SXXm5r3ASqrJ7UV0UZxN5lH1RoCp/ew9NViSVJs9E0lSbSYTSVJtJhNJUm0mE0lSbSYTSVJtXmeirUZEPAi8NzPvmIT3mgUso7q+YklmfrnT71ne92+BX2TmmRPQ1tuoFg/9d+CgchEfEfFbwI8zc7ua7a8DXpmZD9YMVV3AZCJ1xgLgP2TmnlMdSA3/Bbg4M8+Z6kDU/Uwm6hoRcTDV6rc/BV5JdaX0BzLzuxFxOdWv4U+Uus8/Lz2OL1Itv70D1UVn+1PdLmAIOCwzG0tKnBIR84FtgP+VmZeV9t5Jda+al1CtEvvhzLw1Is6kWqNpV+DuzPzDUTEfTnXvi36qK6b/O/AE1VXHLysXZv5e06/6w6lWTj6wPE/g6sw8IyJ2A75HtTDfYaPbzczvjY6HaiHCS4D5VIv6DVNdcEdEfJDqKvNngafLsXzBLRMiYoBqXae3AM9RXUH9J2W7w4GnImL7zDx91MfVHxGXNB3jP87M2zbWXmY+GREHAp+hWlHg+2XfiIiLgccy86Pl+R8C78nMd6Oe4ZyJus3rqL7kXw38PRuWVW9l28x8PfBXwN8BF2TmfKp7OixqqvdUZv4n4K3A30TEK8oKxucCby/veyLw5Yh4adlmD+DVYySSvYHPU33xzS/v/X+pvtSPB36SmQsaiaT4J+BVETG7DBfNKrFAlUC+QrWg5IvaLUNno+M5C3iK6j42R1CWeo+IacCngD/IzH3LMTlgjOO2mCoxzS//+oHzMvM8qvWePjlGIoHqxkvfKMdrMfClsk7UmO2V175ElUhfTbWSxIzS1meB/xoRjR+3J5b9Vw8xmajbrMzMu8rjO4Ed29zuuvLfnwCPZubdTc+b27gIoPRUbqT6Bf1WqsXxlpeexJVUK602hqhua9zQaZQ3A8sz86elzW8Bj1H9Wh9TSSzfLO+5sMTz2xGxPdX6X9e10W5zPIcA/zsz12fmaqqFCcnM56i+vG8p8yi/olqpd7SFwOczcygzR6h6Dgs3Fn+TX2XmNeW9bixle4/T3u8CQ43VjTPzKqoeF+XzfgA4NCL2oUpGN6KeYjJRt2n+Fb+eanXZ0Y+hGo5q9kzT4yE27rmmx/2l7jSqL+8FjX/A64Efl3rrNtLWNF643HejzYFx3h+qL/y3A2+j6qncRDWk9Ergn9tod3Q8zcfl+aRXei7vBP4f8BHgqjb2oZ344YXHsbFd41hurL2+Uds0J+jPAv+t/Pu7zHSdpx5jMlGvWA28FiAidqVadntzLCpt7E71q355+fe2MmxFRLwd+BEbhmE2Zjnw++VWr0TEm6nue3J7i+2+RtUjWkA1R3Ij8NfAstKj2JR2lwF/FBH9EbEDVe+GiNgpIn4OrMnMT1ENP+07xvb/CHwwIgYiop/qbp3faBE/wJyIeEd5r3dS/Qi4f5z2fgT0lWNLRBxGNb/VcC3waqq7l3bLirzaBCYT9YrPAHPLhPXfU92be3NsGxF3AjcAH8rMfyuT0icCV0fE3VRf7Idl5sZ6JACU7U6mml/5MfA/gHdm5hMttnuC6pbFPyzJ45+oksV1m9HumVQ9gvuoktS/lDZ+AZxDNXT3g9LGCWNsfw7VPTzuKjENAKeNF3/xGPCeMiz4F1TzO8Mba6/cAvdw4K/LNv+5tNE4Js9SJZRbSuzqMa4aLGnKlZMdbgZOadzaWb3FnomkKRURv0911t0yE0nvsmciSarNnokkqTaTiSSpNpOJJKk2k4kkqTaTiSSpNpOJJKm2/w/ni0vh6x0muwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.histplot(data=df[df['number_of_words_of_body'] < 70], x='number_of_words_of_body', kde=False, stat='count', binwidth=4)\n",
    "fig.set_xlabel('number of words of body')\n",
    "fig.get_figure().savefig('figures/number_of_words_of_body_less_than_70.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAEJCAYAAADRiELjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApvklEQVR4nO3dfZhdVX3o8e9MZsAUElAYK8hLy4P8oFqJVXxDDFXUplTUKnAFUa4FpKDl9gpVa1KQIq2lF8VW1PJSvKJCBeu1QlpqVExVsL6ALcivPC2mIuEhjUrAQjKTyf1jrwmH4cz7ObP3yXw/z5Mn56y91z6/87b2b9ZZe62+bdu2IUmSJGl+9dcdgCRJkrQQmYhLkiRJNTARlyRJkmpgIi5JkiTVwERckiRJqsFA3QHUYGfgMGA9sLXmWCRpphYBewH/DGyuOZb5YrstqVdN2mYvxET8MGBt3UFI0hwdAfxT3UHME9ttSb2ubZu9EBPx9QA//enPGR2d2Rzqe+yxKxs3PtyVoDqhyfE1OTZodnxNjg2aHV+TY4PZxdff38eTn7wLlLZsgZhVu93k97+psTU1LmhubE2NC5ob20KKa6o2eyEm4lsBRke3zTgRH6vXZE2Or8mxQbPja3Js0Oz4mhwbzCm+hTREY9btdpPf/6bG1tS4oLmxNTUuaG5sCzCutm22F2tKkiRJNViIPeKSpDYi4ivAU4HhUvQ2YAlwMbAYuDYzV5Z9lwGXA0uBrwGnZ+ZIROwHXF2Ok8CJmflwROwOfAo4ANgAHJeZ98/TU5OkRrJHXJJERPQBBwGHZuayzFwGfB+4EngNcAhwWESsKFWuBt6emQcBfcCppfxS4NLMPBj4NrCqlF8ArM3MQ4DLgEu6/6wkqdlMxCVJAFH+vykibo+ItwPPB+7OzHsyc4Qq+T42IvYHFmfmLaXOVaV8EHgpcF1rebl9NFWPOMBngBVlf0lasByaIkkCeDKwBngHMAh8FfgAj7/Sfz2wD7D3BOV7AptK0t5aTmudMoRlEzAE3DfdAPfYY9cZPSGAoaElM64zX5oaW1PjgubG1tS4oLmxGVfFRFySRGZ+E/jm2P2IuAI4n8fPe9sHjFL9mrptGuWU8rF9WvW1bJuWjRsfntGMBkNDS9iw4aGZPMS8aWpsTY0LmhtbU+OC5sa2kOLq7++btBPBoSmSJCLiJRHx8paiPuCHVCvCjXkaVQ/2vROUPwDsFhGLSvlePNbj/eOyHxExQHUR6MbOPgtJ6i32iGteDI+MdvTnns1bRtj04CMdO54kdgfOj4gXUw1NeQtwOvA3EXEgcA9wAnBlZq6LiEcj4vDM/DpwErA6M4cjYi1wPPBp4M3A6nL8G8v9C8v2tZk5zA5q6W6L2XmnyU+xk7WJtnHSwmAirnkxONDPOZfc3LHjXXTW8o4dSxJk5hcj4gXA94BFwEcy85sRcTJwPfAkqmR67ELME4HLImIp8F3gw6X8DOATEbES+E/gjaV8FXBVRNwB/KzU32HtvNPApG3e4OAAw8MjE263jZMWBhNxSRIAmbmKx6YbHCtbAxzaZt/bqWZVGV++DjiyTflPgGM6Fask7QgcIy5JkiTVwERckiRJqoGJuCRJklQDE3FJkiSpBibikiRJUg1MxCVJkqQamIhLkiRJNTARlyRJkmpgIi5JkiTVwERckiRJqoGJuCRJklQDE3FJkiSpBibikiRJUg1MxCVJkqQaDNQdgJpp6W6L2XknPx6SFi7bQUndZgujtnbeaYBzLrm5Y8e76KzlHTuWJM2HubSDtnmSpsOhKZIkSVINTMQlSZKkGpiIS5IkSTUwEZckSZJq0NWLNSPiTcB7yt3VmXl2RBwFXAwsBq7NzJVl32XA5cBS4GvA6Zk5EhH7AVcDTwUSODEzH46I3YFPAQcAG4DjMvP+bj4fSZIkqVO61iMeEb8AfBhYDhwKHBERrwauBF4DHAIcFhErSpWrgbdn5kFAH3BqKb8UuDQzDwa+Dawq5RcAazPzEOAy4JJuPRdJkiSp07o5NGVROf4uwGD5twm4OzPvycwRquT72IjYH1icmbeUuleV8kHgpcB1reXl9tFUPeIAnwFWlP0lSZKkxuva0JTMfCgiVgF3Af8N3AzsDaxv2W09sM8k5XsCm0rS3lpOa50yhGUTMATcN5349thj11k8KxgaWjKrevOlk/ENDnb249Hp43X6vWjye9vk2KDZ8TU5Nmh+fJKk7ulaIh4RzwbeCuwPPEjV+30QsK1ltz5glKrnfDrllPKxfVr1tWyb0saNDzM6Ov7QkxsaWsKGDQ/NqM586mR8Q0NLGB4emXrHGejk8YZHRhkc6NwPOsMjo/zspz/v2PE6aSF97jqtybHB7OLr7++bdUeCJKlZunmx5quANZn5AEBEXAWcDWxt2edpVD3Y9wJ7tSl/ANgtIhZl5tayz1iP94/LfvdGxACwBNjYtWejRhkc6HflT0mS1NO6OUb8duCoiNglIvqAVwO3AhERB0bEIuAEqtlU1gGPRsThpe5JpXwYWAscX8rfDKwut28s9ynb15b9JUmSpMbrWiKemTdRXUT5HeD7VBdrngecDFwP3Ek1fnzsQswTgQ9GxF3ArlQzrgCcAZwWEXcCRwArS/kq4IURcUfZ58xuPRdJkiSp07o6j3hmfgD4wLjiNVTTGY7f93bg+W3K1wFHtin/CXBMRwKVJEmS5pkra0qSJEk1MBGXJEmSamAiLkmSJNXARFySJEmqQVcv1pQk9Z6I+HNgz8w8OSKOAi4GFgPXZubKss8y4HJgKfA14PSyyvF+VAu4PRVI4MTMfDgidgc+BRwAbACOy8z75/eZ9Y7hkdFZr7q6ecsImx58pMMRSeoGE3FJ0nYR8XLgLcANEbEYuBJYDvyolK3IzNVUyfYpmXlLRFwBnAp8FLgUuDQzr4mIVVRTzb4LuIBqvYejI+Ik4BIeWyNC48xl0TIXKJN6h0NTJEkARMRTgPcDF5ai5wN3Z+Y9mTlClXwfGxH7A4sz85ay31WlfBB4KY+tD3EVcGy5fTRVjzhUa0ysKPtL0oJlj7gkaczHgfcC+5b7ewPrW7avB/aZpHxPYFNJ2lvLH3esMoRlEzAE3Dfd4PbYY9eZPBeAWQ/vGDM4OPvT5FR157p9MnN53nN9zbqpqbE1NS5obmzGVTERlyQREacAP8rMNRFxcinuB7a17NYHjM6gnFI+tk+rvpZt07Jx48OMjo4//MSGhpawYcNDM3mIJ9QfHh6ZescJTFZ3cHBgymPP5bFn+7zn+pp1U1Nja2pc0NzYFlJc/f19k3YimIhLkqAar71XRNwGPAXYFdgf2Nqyz9OoerDvBfZqU/4AsFtELMrMrWWfsR7vH5f97o2IAWAJsLFrz0aSeoBjxCVJZOYrMvNZmbkM+CPgC8AKICLiwIhYBJwArM7MdcCjEXF4qX5SKR8G1vLYRZhvBlaX2zeW+5Tta8v+krRgmYhLktrKzEeBk4HrgTuBu3jsQswTgQ9GxF1UvecfLuVnAKdFxJ3AEcDKUr4KeGFE3FH2OXM+noMkNZlDUyRJj5OZV1HNeEJmrgEObbPP7VSzqowvXwcc2ab8J8AxnY1UknqbPeKSJElSDUzEJUmSpBqYiEuSJEk1MBGXJEmSamAiLkmSJNXARFySJEmqgYm4JEmSVAMTcUmSJKkGJuKSJElSDUzEJUmSpBqYiEuSJEk1MBGXJEmSamAiLkmSJNXARFySJEmqgYm4JEmSVAMTcUmSJKkGJuKSJElSDUzEJUmSpBqYiEuSJEk1MBGXJEmSamAiLkmSJNXARFySJEmqgYm4JEmSVIOBbh48Il4NnAvsAtyUmWdFxFHAxcBi4NrMXFn2XQZcDiwFvgacnpkjEbEfcDXwVCCBEzPz4YjYHfgUcACwATguM+/v5vORJEmSOqVrPeIRcQDwMeC1wLOBX4uIFcCVwGuAQ4DDShlUyfbbM/MgoA84tZRfClyamQcD3wZWlfILgLWZeQhwGXBJt56LJEm9YnhklKGhJbP6NzwyWnf40oLSzR7x11H1eN8LEBHHA88A7s7Me0rZ1cCxEXEnsDgzbyl1rwLeFxGXAy+lSubHym8G3gUcXbYBfAb4SEQMZuZwF5+TJEmNNjjQzzmX3DyruhedtbzD0UiaTDcT8QOBLRHxBWA/4IvAHcD6ln3WA/sAe09QviewKTNHxpXTWqcMYdkEDAH3deXZSJIkSR3UzUR8gKrH+kjgYeALwCPAtpZ9+oBRqiEy0ymnlI/t06qvZduU9thj1+nu+jhDQ0tmVW++dDK+wcHOfjyafrwmv7dNjg2aHV+TY4PmxydJ6p5uJuL3A1/KzA0AEfG3wLHA1pZ9nkbVg30vsFeb8geA3SJiUWZuLfuM9Xj/uOx3b0QMAEuAjdMNbuPGhxkdHZ/jT25oaAkbNjw0ozrzqZPxDQ0tYXh4ZOodZ6Dpx2vqe7uQPned1uTYYHbx9ff3zbojQZLULN2cvvCLwKsiYveIWASsAK4DIiIOLGUnAKszcx3waEQcXuqeVMqHgbXA8aX8zcDqcvvGcp+yfa3jwyVJktQrupaIZ+atwJ8B/wTcCawDPgqcDFxfyu6iSs4BTgQ+GBF3AbsCHy7lZwCnlQs6jwBWlvJVwAsj4o6yz5ndei6SJElSp3V1HvHMvJJqusJWa4BD2+x7O/D8NuXrqMaZjy//CXBMRwKVJEmS5pkra0qSJEk16GqPuCSpd0TE+cAbqGaruiIzL3Y1ZEnqHnvEJea2El27f0t3W1z3U5JmJCKWAy+jWgn5ecA7IuJQXA1ZkrrGHnGJua1E146r06nXZObNEfHrpVf76VTnh91xNWRJ6hoTcUkSAJk5HBHvA84GPsvEqx7XshrybOZPn+uCSXNZOGyqunPd3q26TV5kqqmxNTUuaG5sxlUxEZckbZeZ50bEB4C/Aw6iIashw8wXYpvrgk5zXdhssrqDgwNTHrtbjz2Vpi6C1dQFupoaFzQ3toUU11SLsDlGXJJERBxcLsAkM/8b+BzV1LHtVj2ecjXkUt5uNWRmsxqyJO2ITMQlSVDNZnJZROwcETtRXaD5cVwNWZK6ZlqJeERc0absunb7SpLqNZs2OzNvBG4Avgd8B/hGZl6DqyFLUtdMOkY8Ij4KPB04IiKGWjYNUvWeSJIaYq5tdmaeB5w3rszVkCWpS6a6WPMK4FlUjfD1LeUjwC1ta0iS6mKbLUk9ZNJEPDO/DXw7Ir6UmffOU0ySpFmwzZak3jLd6Qv3jYhPAk+hZQqqzHx2V6KSJM2FbbYk9YDpJuIfp1oh7bs8cY5YSVKz2GZLUg+YbiI+kpkXdzUSSVKn2GZLUg+Y7jzi/xoRv9rVSCRJnWKbLUk9YLo94gcA34mIdcAjY4WON5SkRrLNlqQeMN1E/L1djUKS1Em22ZqV4ZFRhoaWzLr+5i0jbHrwkal3lARMPxH/l65GIUnqJNtszcrgQD/nXHLzrOtfdNbyDkYj7fimm4j/F9WV9308dgX+emCfbgQlSZoT22xJ6gHTSsQzc/tFnRGxE3ACEN0KSpI0e7bZktQbpjtrynaZuSUzrwJe0flwJEmdZJstSc01rR7xiHhKy90+4HnAk7sSkSRpTmyzJak3zGaMOMADwO91JSJJ0lzZZktSD5jxGHFJUrPZZktSb5ju0JR+4GxgBTAI3ARcmJkjXYxNkjQLttmS1Bum22vyJ8DLgEuAi4EXAxd1KyhJ0pzYZktSD5juGPHfAJ6XmcMAEXEDcDvw+90KTJI0a7bZktQDptsj3j/WoANk5mZgeJL9JUn1sc2WpB4w3R7x2yLig8BfUl2J/w7g+12LSpI0F7bZktQDptsjfibVHLTfAG4F9qRq2CVJzWObLUk9YNIe8bI08mXA5zPz5FJ2A7AV2NT16CRJ02abLUm9Zaoe8fOBpcDXW8pOBXYHzutOSJKkWbLNlqQeMlUi/lvACZn5wFhBZt4HvBl4XTcDkyTNmG22JPWQqS7W3JKZj4wvzMxNEbG5SzFJkmbHNlu1Gh4ZZWhoyazqbt4ywqYHn/DxlXZoUyXiWyNiSWY+1FoYEUuoVmuTJDWHbbZqNTjQzzmX3DyruhedtbzD0UjNN1Ui/hng8oh4a2b+HCAidgEuB66fzgNExJ8De2bmyRFxFNUqb4uBazNzZdlnWTnmUuBrwOmZORIR+wFXA08FEjgxMx+OiN2BTwEHABuA4zLz/uk/bUnaIc25zZYkzZ+pxoh/CHgQuD8ibomIbwH3Az+luihoUhHxcuAt5fZi4ErgNcAhwGERsaLsejXw9sw8COijurgI4FLg0sw8GPg2sKqUXwCszcxDqGYIuGTqpypJO7wPMYc2W5I0vybtEc/MUeC0iHg/8FxgFLg1M9dPdeCIeArwfuBC4FDg+cDdmXlP2X41cGxE3AkszsxbStWrgPdFxOXAS4HXtpTfDLwLOLpsg6oH6CMRMdi6kpwkLTRzabMlSfNvWitrZuY6YN0Mj/1x4L3AvuX+3kDryWA9sM8k5XsCmzJzZFz5445VhrBsAoaA+2YYoyTtcGbZZkuS5tl0l7ifkYg4BfhRZq6JiJNLcT/VUstj+qh6a6ZbTikf26dVX8u2adljj11nsvt2s70afL50Mr7Bwc5+PBba8Tr5Xiykz12nNTk2aH58kqTu6UoiDhwP7BURtwFPAXYF9qda3W3M06h6sO8F9mpT/gCwW0QsysytZZ+xHu8fl/3ujYgBYAmwcSYBbtz4MKOj4/P8yQ0NLWHDhoem3rEmnYxvaGgJw8MjU+84AwvteJ18LxbK567TmhwbzC6+/v6+WXckSJKaZaqLNWclM1+Rmc/KzGXAHwFfAFYAEREHRsQi4ARgdfkJ9dGIOLxUP6mUDwNrqZJ6qBakWF1u31juU7avdXy4JEmSekm3esSfIDMfLcNUrgeeRJVMX1c2nwhcFhFLge8CHy7lZwCfiIiVwH8Cbyzlq4CrIuIO4GelviRpDiLiXOC4cveGzPwDp52VpO7peiKemVdRzXhCZq6hmkFl/D63U82qMr58HXBkm/KfAMd0NlJJWrhKwv1K4DlU1+f8fUS8EfgAsBz4EXBDRKzIzNVUyfYpmXlLRFxBNe3sR3ls2tlrImIVVcfJu3hs2tmjI+Ikqmlnj0eSFrCuDE2RJPWc9cA7M3NLGer3A+AgyrSzZQarsWln9+eJ084eGxGDVFPLXtdaXm4fTdUjDtW0syvK/pK0YM3b0BRJUnNl5h1jtyPiGVRDVP6CBk07O5uLVOc6K81cZlOaqu5ctzex7lzrT/V+NXWWoabGBc2NzbgqJuKSpO0i4pnADcA5wAhVr/iYWqednelsV3OdNWeus0dNVndwcGDKY3frsbtZd671J3u/mjoLUlPjgubGtpDimmqmK4emSJIAKLNXrQHenZmfYOLpZaecdraUt5t2ltlOOytJOxoTcUkSEbEv8HnghMy8phTfitPOSlLXODRFkgRwNtXUshdHxFjZx4CTcdpZzYPhkdFZjxHfvGWETQ8+0o2wpK4yEZe6YDonlJkcS+q2zDwLOGuCzU47q64bHOjnnEtunnj7JOPqLzprebfCkrrKRFzqgqlOKDPhCUaSpB2TY8QlSZKkGpiIS5IkSTUwEZckSZJqYCIuSZIk1cBEXJIkSaqBibgkSZJUAxNxSZIkqQYm4pIkSVINTMQlSZKkGriypiRJ6mnDI6MMDS2Zdf3NW0bY9OAjHYxImh4TcUmS1NMGB/o555KbZ13/orOWdzAaafocmiJJkiTVwERckiRJqoGJuCRJklQDE3FJkiSpBibikiRJUg1MxCVJkqQamIhLkiRJNXAecUmStKDNZUGg4ZHRDkejhcREXJIkLWhzWRDIxYA0Fw5NkSRJkmpgIi5JkiTVwERckiRJqoGJuCRJklQDE3FJkiSpBibikiRJUg1MxCVJkqQamIhLkiRJNejqgj4RcS5wXLl7Q2b+QUQcBVwMLAauzcyVZd9lwOXAUuBrwOmZORIR+wFXA08FEjgxMx+OiN2BTwEHABuA4zLz/m4+H0mSpFZzWZVz85YRNj34SIcjUi/pWiJeEu5XAs8BtgF/HxFvBD4ALAd+BNwQESsyczVVsn1KZt4SEVcApwIfBS4FLs3MayJiFbAKeBdwAbA2M4+OiJOAS4Dju/V8JEmSxnNVTs1FN4emrAfemZlbMnMY+AFwEHB3Zt6TmSNUyfexEbE/sDgzbyl1ryrlg8BLgetay8vto6l6xAE+A6wo+0uSJEmN17VEPDPvGEusI+IZVENURqkS9DHrgX2AvSco3xPYVJL21nJa65Ttm4ChrjwZSZIkqcO6OkYcICKeCdwAnAOMUPWKj+mjSs77qYavTFVOKR/bp1Vfy7Yp7bHHrtPd9XFmOw5svnQyvsHBzn48PN7szGX84UTHGxzo7N/gTf5eNDk2aF58EbEU+AbwW5n5Q6/rkaTu6fbFmocD1wP/q4zxXg7s1bLL04D7gHsnKH8A2C0iFmXm1rLPfWWfH5f97o2IAWAJsHG6sW3c+DCjo+Nz/MkNDS1hw4aHZlRnPnUyvqGhJQwPj0y94wx4vNmZy/jDdi46a3lHP8dN/l40OTaYXXz9/X2z7kiYSkS8ALiM0mESEYuBK/G6Hknqiq4NTYmIfYHPAydk5jWl+NZqUxwYEYuAE4DVmbkOeLQk7gAnlfJhYC2PNdZvBlaX2zeW+5Tta8v+kqTZORU4k8c6PJ6P1/VIXTP2i+ds/y3dbXHdT0Fz1M0e8bOBJwEXR8RY2ceAk6l6yZ9ElUyPNdgnApeVn0W/C3y4lJ8BfCIiVgL/CbyxlK8CroqIO4CflfqSpFnKzFMAWtrsia7fmfN1PRExdl3PfUzTbH4JmOvQn7kMMZuq7ly3N7Futx97su1NjnvCegP9/OGlX5/14154xuFTfsabNvxtjHFVupaIZ+ZZwFkTbD60zf63U/W+jC9fBxzZpvwnwDFzi1KSNInpXr/T9et6YOZDCuc6NGmuQ/Qmqzs4ODDlsbv12N2s283Hnuo1a2rc3awLTPoZb+rwvIUU11TDCV1ZU5I0kYmu35nyup5S3u66HmZzXY8k7Yi6PmuK5k+nZ9eQtOBtv64HuIfqup4rM3NdRDwaEYdn5tdpua4nIsau6/k07a/ruRCv65EkwER8h9LJ2TVc7UtSZj4aESfjdT1SI02nA26i7Zu3jLDpwUe6EZZmwERckvQ4mflLLbfX4HU9UiNN1QE32bh6O9yawTHikiRJUg1MxCVJkqQaODRFkiRpgZnrBA+OMe8ME3FJkqQFZq4TPDjGvDMcmiJJkiTVwERckiRJqoFDUyRJkjQjcxljPjwy2uFoepeJuCRJkmZkLmPMHV/+GIemSJIkSTWwR1ySJEnzZi7DWna0aRNNxCVJkjRvHNbyGIemSJIkSTWwR1xaYOa6mlq740mSNB92tBVBTcSlBWauq6mNt6P9TChJaq4dbUVQh6ZIkiRJNTARlyRJkmrg0BRJ0g6p09dDSFKnmYhLknZIO9pYUkk7HoemSJIkSTUwEZckSZJqYCIuSZIk1cBEXJIkSaqBibgkSZJUAxNxSZIkqQZOXyhpTjo9V/PmLSNsevCRjh1PkqSmMhGXNCdznat5POduliR1y1SdR5Nt60ZHkYm4JEmSFoTJOo8GBwcYHh6ZsG43OoocIy5JkiTVwERckiRJqoGJuCRJklQDx4hLapROzsIyPDLakeNIktQNJuKSGqWTs7A4A4skqckcmiJJkiTVoKd7xCPiBGAlMAh8KDM/UnNIkhrExYaaxTZbkh6vZxPxiHg68H7gucBm4BsR8ZXMvLPeyCQ1RacXG7rwzCM6mtgvpDHsttmS9EQ9m4gDRwFfzsyfAETEdcAbgPOnqLcIoL+/b1YPOtt67ey65EnsvFNn34InL9m5kcfyeM051kI7XiePNTjQz4VX3tKx4/3hW1844zalZf9FHQtkfsy2zYY5tNtzff/nUn+yugODA4wMT/4Wduuxu1m3m4891WvW1Li7WXeq+r5mM6s/ne9lp9vsvm3bts3ogE0REe8BdsnMleX+KcDzM/O0Kaq+BFjb7fgkqcuOAP6p7iCmaw5tNthuS+p9bdvsXu4R7wda/4roA6bzO+8/U70Y64GtXYhLkrppEbAXVVvWS2bbZoPttqTeNWmb3cuJ+L1UDfOYpwH3TaPeZnqoF0mS2vj3ugOYhdm22WC7Lam3Tdhm93Ii/iXgvIgYAn4OvB6Yzk+ckqT5Z5stSeP07Dzimflj4L3AV4DbgE9n5rdqDUqS1JZttiQ9Uc9erClJkiT1sp7tEZckSZJ6mYm4JEmSVAMTcUmSJKkGJuKSJElSDXp5+sJ5FREnACuBQeBDmfmRmkPaLiLOBY4rd2/IzD+oM552IuLPgT0z8+S6Y2kVEa8GzgV2AW7KzLNqDulxIuJNwHvK3dWZeXad8QBExFLgG8BvZeYPI+Io4GJgMXDt2MqJDYntNOD3qBaS+Tbwtszc0pT4WsrfDrwhM4+sKbQdTtPa7CZ+b9qdO5oQV4ntfOANVN/dKzLz4qbEVuLbfk5rSlwR8RXgqcBwKXobsKTu2NqdZ5vwmpXVfd/eUvTLwCeBz89nbPaIT0NEPB14P9Uyy8uA0yLiV2oNqigf5lcCz6GK7bkR8bpagxonIl4OvKXuOMaLiAOAjwGvBZ4N/FpErKg1qBYR8QvAh4HlwKHAEeX9rjOmF1AtrHJQub8YuBJ4DXAIcFhdr2Gb2A4CzgFeTPX+9gNn1hFbu/hayn8FeHctQe2gmtZmN/F7M8G54411x1ViWw68jOp7+zzgHRFxaBNiK/FtP6c14b0scfRRfb4OzcxlmbkM+H7dsU1ynq39NcvMy1teqxOBB4APzHdsJuLTcxTw5cz8SWb+HLiO6i/1JlgPvDMzt2TmMPADYL+aY9ouIp5CdUK8sO5Y2ngd1V+795bX7njg1ppjarWI6ju6C1Wv3iDwSK0RwalUyezYiojPB+7OzHsycwS4Gji2IbFtBs7IzE2ZuQ34F+r9boyPj4jYGfg48Ed1BbWDalqb3cTvTbtzx0ENiIvMvBn49RLDU6l+vd+9CbG1Oac14b0EiPL/TRFxe/mVrQmxtTvP/ncD4hrvo8AfAgcwz7E5NGV69qZqtMasp/qA1y4z7xi7HRHPoPqZ8fD6InqCj1Mt4rFv3YG0cSCwJSK+QJWgfRFYVW9Ij8nMhyJiFXAXVcN1M9VP23XGdApAxFib3/a7sc88hwU8MbbMXAesK2VDVD9BnlxHbCWe8a8dwJ9Q9b7cU0dMO7BGtdlN/N5McO74i7rjGpOZwxHxPuBs4LM04DUrxp/TmhLXk4E1wDuoOm2+StW7W3ds7c6zdzQgru3Kr0OLM/Oz5VeheY3NHvHp6acapzamDxitKZa2IuKZwD8C52Tm3XXHA9vHX/0oM9fUHcsEBqh6zn4HeBHwAho0hCYing28FdifqrHfSnVSapJe+G48neoEdUVmfrXmcLaLiFcA+2XmX9cdyw6o6Z/LxsTXeu4A/qMpcQFk5rnAEFXSexA1xzbBOa0R72VmfjMz35yZD2bmfwFXAOc3ILZ259kDGhBXq7dRjQmHGt5PE/HpuRfYq+X+02j5ebluEXE4VaLx7sz8RN3xtDgeeGVE3EbVIBwTER+sN6THuR/4UmZuyMxHgL+lIb90FK8C1mTmA5m5GbgKOLLWiJ6o6d+Ng6l+RfhEZv5x3fGM80bgmeX7cTnwvIi4tt6QdhiN/lzSkPjanDuaEtfBEbEMIDP/G/gcVdtXd2xPOKcBpzQgLiLiJWXs+pg+4IfUH1u78+xRDYgLgIjYieo6rC+Uonn/Djg0ZXq+BJxXft7+OfB64LR6Q6pExL5UV/gen5lfrjmcx8nMV4zdjoiTgSMz8/fri+gJvgh8IiJ2Bx4CVlC9lk1xO/BnEbEL1dCUVwP/XG9IT3ArEBFxINXwihOohlrULiKWADcB783MT9Ydz3iZ+dax2xFxJHBeZh5fX0Q7lMa22UXt35sJzh21x1UcALwvIl5C1Tv5GqohIRfVGVu7cxpwOnB3A16z3YHzI+LFVENT3lJi+5uaY2t3nr0OeHcDXjOoLiD9t3ItCdTwHbBHfBoy88dUY8K+AtwGfDozv1VrUI85G3gScHFE3Fb+nV53UL0gM28F/oxqNoM7qcYTN2aYQGbeBHwG+A7V1e+DwJ/WGtQ4mfko1bjr66lew7uoGtkmOAX4ReCdLd+N8+sOSt3X8Da7Kd+bJ5w7Skx1x0Vm3gjcAHyPqv37RmZe04TYxmvIe0lmfpHHv2ZXZuY3645tgvPsR+uOq8UBVL3gQD3vZ9+2bdum3kuSJElSR9kjLkmSJNXARFySJEmqgYm4JEmSVAMTcUmSJKkGJuKSJElSDUzE1bMi4ocR8bx5eqylEfH1iLgjIn57Ph6zPO5fRsR5HTrWKyNiXUR8KyIWj9t2WUQ8t9y+vCz5O778qxHxhk7EImlhsJ2e8bHattMR8UsR8XAHjv9wRPzSXI+jznFBH2l6lgG/mJkH1h3IHPwP4LLMvKDNtldQLZhBZp7SrlySGm4ZO3Y7rR2Qibi6pqwW+H7gP4BnUS1I87bM/HpEXAX8a2b+edl3+/2I+CHwaeBlwJOpFgM4HHguMAwck5ljS86eGRGHAjsD/yczryzHezWwEtiJalXKszPzm6XX4kXA3sDtmfmmcTG/FjiX6teih4D/DTxItbLW08uiFy8qS/WO7f/OzDyi3E/gmsw8NyL2Ab4F7EO1FPLjjpuZ3xofD3AG1XLnhwLrgRGqhRCIiN+lWiltC/BoeS3vHBf/IHAx8HJgK9UqYb9f6r0WeCQidsvMc1rqvL88/qci4s3AB4C/BJ4zrrz1cV5c9tulPM77yoISknqI7XRvtNNFf0Rc3vIa/15m3jLR8TLzoYg4AvgLqhVK/7k8NyLiMuCBzHxvuf8m4PWZ+To0rxyaom57AVXD+xyqVSsvnGa9J2XmC4E/Av4KuCQzDwV+RLXq1ZhHMvPXqHpu/yQinhkRzyiP85vlcU8DPleWigfYH3hOm8b9YOBjVI3RoeWx/x9VQ3sK8O+ZuWyscS/+AXh2ROxefu5bWmKBqlH/PHBQu+NGxNI28bwPeAQ4GDgWiBLbIuBDwG9k5mHlNXlJm9dtJdXJ4tDyrx+4KDMvAr4AfHB8414a4vuAE8sqaJOWR8STqd7Lk8pr/xrgoxGxX5t4JDWf7XTD2+liMfCP5fVaCXw2Inaa6Hhl22ep/gh5DtVKs2PDXT4C/M+IGOuQPa08f80zE3F127rMvK3c/i7wlGnWu778/+/A/Zl5e8v91mOMDae4D7iJqkfgFcBewJrSM/IpYBQY+7nylswcafOYLwPWZOZ/lGN+GXiAqvehrdLYf6k85ooSzy9HxG5UCer10zhuazxHAf83M7dl5gbgb0udrVQN6jci4i+BnwFXtAlpBfCxzBzOzFGqnpAVE8U/Sy+ien0/X17fG6l6W57d4ceRND9sp3ujnf5ZZl5bHuumUnbwJMf7VWA4M9eUOp+h6umnvN/3AEdHxCFUifxNaN45NEXd1torsQ3oa3Mbqp8mW21uuT08yfG3ttzuL/sOUDWox49tiIh9qXp3XwdMdMHLohJXq36qn2q3TBLD3wK/CexO9fPswVQ/Lz4L+CrwK5MclzbxtL4u209EmfmmiHgW1Ung3cBJwHFTPIfWx+mURcAPMvMFYwURsTewocOPI2l+2E73Rju9ddz9sddysuP1javT+sfNR4C3Av8G/FVmjn/+mgf2iKsuG4DnwfYkbvksj3NyOcZ+VA3fmvLvleUnTCLiN4Hv89hPchNZA7wqIg4o9V4G7Es13m4yf0fVw7OMaqzhTcAfA6tLD8lMjrsa+J2I6C9DQF5T6uwZET8CNmbmh6h+ijysTf2/B343IgYjoh84E/jHKeKHqnFudyJoV34L8IyIeGmJbRlwN/D0aTyOpN5hO92sdnqPiPit8livpvoD6u5Jjvd9oK+8tkTEMVTj+cdcR3Ut0BuoxterBibiqstfAHuVi2b+GvjyLI/zpIj4LtXwiHdk5r+VC2NOA66JiNupGttjMnPSqZ9KvTOoxin+K/CnwKsz88Ep6j0I/AD4XmnQ/4GqAb9+Fsc9j6qH4y6qE8e/lGP8F3AB1c+43ynHOLVN/QuA+4HbSkyDwFmTxV98Drg6Il45VXn5Kfb1VGMQbwc+STVe/IfTeBxJvcN2ulnt9APA68tQnvdQjWcfmeh4mTlM1ev/x6XOb5djjL0mW6iS8W+U2FWDvm3b/CVCkiRpISkXxn4NODMzb6k7noXKHnFJkqQFJCJeRTW7zWqT8HrZIy5JkiTVwB5xSZIkqQYm4pIkSVINTMQlSZKkGpiIS5IkSTUwEZckSZJqYCIuSZIk1eD/A91OIN4a4g7TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print altogether\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(12)\n",
    "ax[0].set_xlabel('number of words of title')\n",
    "ax[1].set_xlabel('number of words of body')\n",
    "sns.histplot(data=df[df['number_of_words_of_title'] < 15], x='number_of_words_of_title', kde=False, stat='count', binwidth=1, ax=ax[0])\n",
    "sns.histplot(data=df[df['number_of_words_of_body'] < 70], x='number_of_words_of_body', kde=False, stat='count', binwidth=4, ax=ax[1])\n",
    "fig.savefig('figures/title_words_less_than_15_body_words_less_than_70.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load glove embeddings 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n"
     ]
    }
   ],
   "source": [
    "glove2word2vec('glove.6B/glove.6B.100d.txt', 'tmpfile_glove')\n",
    "glove_embeddings_model = KeyedVectors.load_word2vec_format('tmpfile_glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_glove_embedding(word):\n",
    "    if word not in glove_embeddings_model:\n",
    "        return np.zeros(100, dtype='float32')\n",
    "    return glove_embeddings_model.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_glove_embedding(sentence):\n",
    "    word_embeddings = [glove_embeddings_model.get_vector(word) if word in glove_embeddings_model else np.zeros(100, dtype='float32') for word in sentence.split()]\n",
    "    if len(word_embeddings) == 0:\n",
    "        return np.zeros(100, dtype='float32')\n",
    "    return np.mean(word_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fasttext_input'] = '__label__' + df['label'].map(str) + ' ' + df['title'] + ' ' + df['body']\n",
    "train_input, test_input = train_test_split(df.fasttext_input.values, test_size=0.33, random_state=42)\n",
    "np.savetxt('train.txt', train_input, fmt='%s')\n",
    "np.savetxt('test.txt', test_input, fmt='%s')\n",
    "fasttext_model = fasttext.train_supervised('train.txt', dim=100, epoch=5)\n",
    "fasttext_model.test('test.txt')\n",
    "df.drop('fasttext_input', axis=1, inplace=True)\n",
    "embeddings_lookup = {word: fasttext_model.get_word_vector(word) for word in fasttext_model.get_words()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe + logistic regression classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.body, df.label, test_size=0.33, random_state=42)\n",
    "X_train = [get_sentence_glove_embedding(s) for s in X_train.values]\n",
    "X_test = [get_sentence_glove_embedding(s) for s in X_test.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_classifier(use_global_random_number=True):\n",
    "    if use_global_random_number:\n",
    "        random_state = global_random_number\n",
    "    else:\n",
    "        random_state = get_random_number()\n",
    "    logit_clf = LogisticRegression(random_state=random_state, solver='liblinear').fit(X_train, y_train)\n",
    "    predicted_labels = logit_clf.predict(X_test)\n",
    "    true_labels = y_test\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, predicted_labels)\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_evaluation_results = [run_logistic_regression_classifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>GloVe + logistic regression results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation_results(logit_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe + knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_regression_classifier():\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "    predicted_labels = knn_clf.predict(X_test)\n",
    "    true_labels = y_test\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, predicted_labels)\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_evaluation_results = [run_knn_regression_classifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>GloVe + knn results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_evaluation_results(knn_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fasttext_classifier():\n",
    "    df['fasttext_input'] = '__label__' + df['label'].map(str) + ' ' + df['title'] + ' ' + df['body']\n",
    "    train_input, test_input = train_test_split(df.fasttext_input.values, test_size=0.33, random_state=42)\n",
    "    np.savetxt('train.txt', train_input, fmt='%s')\n",
    "    np.savetxt('test.txt', test_input, fmt='%s')\n",
    "    fasttext_model = fasttext.train_supervised('train.txt', dim=100, epoch=5)\n",
    "    fasttext_model.test('test.txt')\n",
    "    df.drop('fasttext_input', axis=1, inplace=True)\n",
    "    embeddings_lookup = {word: fasttext_model.get_word_vector(word) for word in fasttext_model.get_words()}\n",
    "\n",
    "    _, test_df = train_test_split(df, test_size=0.33, random_state=42)\n",
    "    predicted_labels = [int(res[0].split('__label__')[1]) for res in fasttext_model.predict(test_df['body'].values.tolist())[0]]\n",
    "    true_labels = test_df['label'].values\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, predicted_labels)\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_evaluation_results = []\n",
    "for num in global_random_numbers:\n",
    "    fasttext_evaluation_results.append(run_fasttext_classifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Fasttext results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_evaluation_results(fasttext_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.body, df.label, test_size=0.33, random_state=42)\n",
    "x_train = [get_sentence_glove_embedding(s) for s in x_train.values]\n",
    "x_test = [get_sentence_glove_embedding(s) for s in x_test.values]\n",
    "\n",
    "x_train = torch.tensor(x_train).float()\n",
    "y_train = torch.tensor(y_train.values).float()\n",
    "\n",
    "x_test = torch.tensor(x_test).float()\n",
    "y_test = torch.tensor(y_test.values).float()\n",
    "\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "BATCH_SIZE = 255\n",
    "\n",
    "# generate train dataset and train dataloader\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# generate test dataset\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self) : \n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(100 , 250)\n",
    "        self.linear2 = torch.nn.Linear(250, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp_classifier():\n",
    "    # Initialize the MLP\n",
    "    mlp = MLP().to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "\n",
    "    mlp.train()\n",
    "    # Run the training loop\n",
    "    for epoch in range(0, 50):\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "            # Get inputs\n",
    "            targets = targets.squeeze()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = mlp(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(f'Epoch: {epoch}, Epoch loss {loss.item()}')\n",
    "    # Process is complete.\n",
    "    print('Training process has finished.')\n",
    "    print('Final loss', loss.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mlp.eval()\n",
    "        pred = mlp(test_dataset.tensors[0].to(device))\n",
    "        y_true = test_dataset.tensors[1].tolist()\n",
    "        y_pred = torch.round(torch.tensor(pred.tolist()).squeeze())\n",
    "        results = calculate_accuracy_precision_recall(y_true, y_pred)\n",
    "\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_evaluation_results = []\n",
    "for num in global_random_numbers:\n",
    "    torch.manual_seed(num)\n",
    "    mlp_evaluation_results.append(run_mlp_classifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>GloVe + MLP results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_evaluation_results(mlp_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def create_graph_of_words(text, window_size):\n",
    "    text = text.split()\n",
    "    G = nx.Graph()\n",
    "    for i, word in enumerate(text):\n",
    "        #embedding = fasttext_model.get_word_vector(word)\n",
    "        embedding = embeddings_lookup.get(word, np.zeros(100, dtype='float32'))\n",
    "        G.add_node(word, x=embedding)\n",
    "        for j in range(i + 1, i + window_size):\n",
    "            if j < len(text):\n",
    "                G.add_edge(word, text[j])\n",
    "    return G\n",
    "\n",
    "def create_graph_of_words_for_pytorch(text, window_size):\n",
    "    return from_networkx(create_graph_of_words(text, window_size))\n",
    "\n",
    "def generate_pytorch_geometric_graphs(window_size):\n",
    "    pyg_graphs = []\n",
    "    for s in tqdm(df['body'].values):\n",
    "        pyg_graphs.append(create_graph_of_words_for_pytorch(s, window_size))\n",
    "    print('finished...')\n",
    "    for i, label in enumerate(df['label'].values):\n",
    "        pyg_graphs[i].y = torch.tensor(label).float()\n",
    "    \n",
    "    pyg_graphs = [g for g in pyg_graphs if g.num_nodes != 0]\n",
    "    return pyg_graphs\n",
    "\n",
    "class GATClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #torch.manual_seed(12345)\n",
    "        \n",
    "        #self.conv1 = GATConv(100, 10, heads=3)\n",
    "        self.conv1 = SGConv(100, 50, K=1)\n",
    "        self.linear1 = torch.nn.Linear(10*5, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data, batch):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        h = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear1(h)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return h, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 407799/407799 [20:21<00:00, 333.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n"
     ]
    }
   ],
   "source": [
    "pytorch_geometric_graphs = generate_pytorch_geometric_graphs(window_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pyg_graphs, test_pyg_graphs = train_test_split(pytorch_geometric_graphs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gat_classifier(train_pyg_graphs, test_pyg_graphs, train_batch_size=300, learning_rate=0.001, num_epoch=10):\n",
    "    train_loader = DataLoader(train_pyg_graphs, batch_size=train_batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_pyg_graphs, batch_size=200, shuffle=False)\n",
    "    \n",
    "    gat_model = GATClassifier().to(device)\n",
    "    print(gat_model)\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    optimizer = torch.optim.Adam(gat_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    gat_model.train()\n",
    "    for epoch in range(0, num_epoch):\n",
    "        for i, data in enumerate(train_loader):  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            try:\n",
    "                _, out = gat_model(data, data.batch)  # Perform a single forward pass.\n",
    "            except Exception as e:\n",
    "                print(data)\n",
    "                print(data.x)\n",
    "                print(data.y)\n",
    "            out = out.squeeze()\n",
    "            y = data.y.squeeze()\n",
    "            loss = loss_function(out, y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "        print(f'Epoch: {epoch}, Epoch loss {loss.item()}')\n",
    "\n",
    "    print('Training process has finished.')\n",
    "    print('Final loss', loss.item())\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        gat_model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            _, out = gat_model(data, data.batch)\n",
    "            pred_labels.extend(torch.round(out.squeeze()).tolist())\n",
    "            true_labels.extend(data.y.tolist())\n",
    "            \n",
    "    #print('true labels ----')\n",
    "    #print(true_labels)\n",
    "    #print('pred labels ----')\n",
    "    #print(pred_labels)\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, pred_labels)\n",
    "    \n",
    "    print(results)\n",
    "    return {\n",
    "        'model': gat_model,\n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 0, Epoch loss 0.3446064889431\n",
      "Epoch: 1, Epoch loss 0.3434496819972992\n",
      "Epoch: 2, Epoch loss 0.34211021661758423\n",
      "Epoch: 3, Epoch loss 0.35209256410598755\n",
      "Epoch: 4, Epoch loss 0.353280246257782\n",
      "Epoch: 5, Epoch loss 0.34084728360176086\n",
      "Epoch: 6, Epoch loss 0.35327771306037903\n",
      "Epoch: 7, Epoch loss 0.3437592685222626\n",
      "Epoch: 8, Epoch loss 0.34147462248802185\n",
      "Epoch: 9, Epoch loss 0.357673317193985\n",
      "Training process has finished.\n",
      "Final loss 0.357673317193985\n",
      "(0.8027776539301796, 0.8166833015757796, 0.7892667670227848)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.34338057041168213\n",
      "Epoch: 1, Epoch loss 0.35319092869758606\n",
      "Epoch: 2, Epoch loss 0.34215882420539856\n",
      "Epoch: 3, Epoch loss 0.34182316064834595\n",
      "Epoch: 4, Epoch loss 0.3524443209171295\n",
      "Epoch: 5, Epoch loss 0.35293805599212646\n",
      "Epoch: 6, Epoch loss 0.3540140390396118\n",
      "Epoch: 7, Epoch loss 0.353135883808136\n",
      "Epoch: 8, Epoch loss 0.34889352321624756\n",
      "Epoch: 9, Epoch loss 0.34355491399765015\n",
      "Training process has finished.\n",
      "Final loss 0.34355491399765015\n",
      "(0.802681052803662, 0.8155209573618292, 0.7908013387311285)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.3479885458946228\n",
      "Epoch: 1, Epoch loss 0.3509548008441925\n",
      "Epoch: 2, Epoch loss 0.3532697558403015\n",
      "Epoch: 3, Epoch loss 0.33759957551956177\n",
      "Epoch: 4, Epoch loss 0.35386544466018677\n",
      "Epoch: 5, Epoch loss 0.35054337978363037\n",
      "Epoch: 6, Epoch loss 0.3459223508834839\n",
      "Epoch: 7, Epoch loss 0.34807589650154114\n",
      "Epoch: 8, Epoch loss 0.3553924858570099\n",
      "Epoch: 9, Epoch loss 0.34869226813316345\n",
      "Training process has finished.\n",
      "Final loss 0.34869226813316345\n",
      "(0.8028593933449255, 0.8167137910700516, 0.7894275316779445)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.3446800112724304\n",
      "Epoch: 1, Epoch loss 0.35039666295051575\n",
      "Epoch: 2, Epoch loss 0.3528206944465637\n",
      "Epoch: 3, Epoch loss 0.3417188227176666\n",
      "Epoch: 4, Epoch loss 0.3507686257362366\n",
      "Epoch: 5, Epoch loss 0.34774115681648254\n",
      "Epoch: 6, Epoch loss 0.343904048204422\n",
      "Epoch: 7, Epoch loss 0.3552398979663849\n",
      "Epoch: 8, Epoch loss 0.36225634813308716\n",
      "Epoch: 9, Epoch loss 0.3561335504055023\n",
      "Training process has finished.\n",
      "Final loss 0.3561335504055023\n",
      "(0.8027553613625217, 0.8168091383614494, 0.7890183125557195)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.34802567958831787\n",
      "Epoch: 1, Epoch loss 0.3522244393825531\n",
      "Epoch: 2, Epoch loss 0.3576834797859192\n",
      "Epoch: 3, Epoch loss 0.3490036725997925\n",
      "Epoch: 4, Epoch loss 0.34919270873069763\n",
      "Epoch: 5, Epoch loss 0.34760960936546326\n",
      "Epoch: 6, Epoch loss 0.3494594693183899\n",
      "Epoch: 7, Epoch loss 0.3423284590244293\n",
      "Epoch: 8, Epoch loss 0.34679076075553894\n",
      "Epoch: 9, Epoch loss 0.34588634967803955\n",
      "Training process has finished.\n",
      "Final loss 0.34588634967803955\n",
      "(0.8027850847860657, 0.8163894302678693, 0.7897344460196133)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.3525170683860779\n",
      "Epoch: 1, Epoch loss 0.352100670337677\n",
      "Epoch: 2, Epoch loss 0.3556331992149353\n",
      "Epoch: 3, Epoch loss 0.351597398519516\n",
      "Epoch: 4, Epoch loss 0.3465810716152191\n",
      "Epoch: 5, Epoch loss 0.34838107228279114\n",
      "Epoch: 6, Epoch loss 0.3489486873149872\n",
      "Epoch: 7, Epoch loss 0.35474520921707153\n",
      "Epoch: 8, Epoch loss 0.3499526381492615\n",
      "Epoch: 9, Epoch loss 0.337254136800766\n",
      "Training process has finished.\n",
      "Final loss 0.337254136800766\n",
      "(0.8027404996507498, 0.8170050415587955, 0.7886821682767491)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.3440572917461395\n",
      "Epoch: 1, Epoch loss 0.3449517786502838\n",
      "Epoch: 2, Epoch loss 0.3518224358558655\n",
      "Epoch: 3, Epoch loss 0.3567434251308441\n",
      "Epoch: 4, Epoch loss 0.3499496579170227\n",
      "Epoch: 5, Epoch loss 0.35461464524269104\n",
      "Epoch: 6, Epoch loss 0.34980958700180054\n",
      "Epoch: 7, Epoch loss 0.3534184396266937\n",
      "Epoch: 8, Epoch loss 0.3512839078903198\n",
      "Epoch: 9, Epoch loss 0.34532132744789124\n",
      "Training process has finished.\n",
      "Final loss 0.34532132744789124\n",
      "(0.8028296699213815, 0.8162245406368427, 0.7900998202358855)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.35184386372566223\n",
      "Epoch: 1, Epoch loss 0.34090501070022583\n",
      "Epoch: 2, Epoch loss 0.34919074177742004\n",
      "Epoch: 3, Epoch loss 0.34839195013046265\n",
      "Epoch: 4, Epoch loss 0.35706403851509094\n",
      "Epoch: 5, Epoch loss 0.34120485186576843\n",
      "Epoch: 6, Epoch loss 0.34864678978919983\n",
      "Epoch: 7, Epoch loss 0.35276496410369873\n",
      "Epoch: 8, Epoch loss 0.3608187437057495\n",
      "Epoch: 9, Epoch loss 0.3539724051952362\n",
      "Training process has finished.\n",
      "Final loss 0.3539724051952362\n",
      "(0.8026959145154339, 0.8171036488390058, 0.788419098841033)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.34718793630599976\n",
      "Epoch: 1, Epoch loss 0.36111199855804443\n",
      "Epoch: 2, Epoch loss 0.34730273485183716\n",
      "Epoch: 3, Epoch loss 0.3537960648536682\n",
      "Epoch: 4, Epoch loss 0.3469322919845581\n",
      "Epoch: 5, Epoch loss 0.35828620195388794\n",
      "Epoch: 6, Epoch loss 0.3523618280887604\n",
      "Epoch: 7, Epoch loss 0.35021016001701355\n",
      "Epoch: 8, Epoch loss 0.3460008502006531\n",
      "Epoch: 9, Epoch loss 0.3540070354938507\n",
      "Training process has finished.\n",
      "Final loss 0.3540070354938507\n",
      "(0.8028073773537237, 0.81627352079495, 0.7899682855180276)\n",
      "GATClassifier(\n",
      "  (conv1): SGConv(100, 50, K=1)\n",
      "  (linear1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Epoch loss 0.34989869594573975\n",
      "Epoch: 1, Epoch loss 0.3558759391307831\n",
      "Epoch: 2, Epoch loss 0.3498704731464386\n",
      "Epoch: 3, Epoch loss 0.3509600758552551\n",
      "Epoch: 4, Epoch loss 0.34485843777656555\n",
      "Epoch: 5, Epoch loss 0.34759750962257385\n",
      "Epoch: 6, Epoch loss 0.3573731482028961\n",
      "Epoch: 7, Epoch loss 0.34890836477279663\n",
      "Epoch: 8, Epoch loss 0.3452059328556061\n",
      "Epoch: 9, Epoch loss 0.34611186385154724\n",
      "Training process has finished.\n",
      "Final loss 0.34611186385154724\n",
      "(0.8027776539301796, 0.8162910826486225, 0.7898659807374713)\n"
     ]
    }
   ],
   "source": [
    "gat_evaluation_results = []\n",
    "for num in global_random_numbers:\n",
    "    torch.manual_seed(num)\n",
    "    gat_evaluation_results.append(run_gat_classifier(train_pyg_graphs, test_pyg_graphs)['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Our approach results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy | Avg precision | Avg recall\n",
      "0.8028+-0.0001, 0.8165+-0.0004, 0.7895+-0.0007\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(gat_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove + GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_of_words_glove(text, window_size):\n",
    "    text = text.split()\n",
    "    G = nx.Graph()\n",
    "    for i, word in enumerate(text):\n",
    "        #embedding = fasttext_model.get_word_vector(word)\n",
    "        embedding = get_word_glove_embedding(word)\n",
    "        G.add_node(word, x=embedding)\n",
    "        for j in range(i + 1, i + window_size):\n",
    "            if j < len(text):\n",
    "                G.add_edge(word, text[j])\n",
    "    return G\n",
    "\n",
    "def create_graph_of_words_for_pytorch_glove(text, window_size):\n",
    "    return from_networkx(create_graph_of_words_glove(text, window_size))\n",
    "\n",
    "def generate_pytorch_geometric_graphs_glove(window_size):\n",
    "    pyg_graphs = []\n",
    "    for s in tqdm(df['body'].values):\n",
    "        pyg_graphs.append(create_graph_of_words_for_pytorch_glove(s, window_size))\n",
    "    print('finished...')\n",
    "    for i, label in enumerate(df['label'].values):\n",
    "        pyg_graphs[i].y = torch.tensor(label).float()\n",
    "    \n",
    "    pyg_graphs = [g for g in pyg_graphs if g.num_nodes != 0]\n",
    "    return pyg_graphs\n",
    "\n",
    "class GATGloveClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #torch.manual_seed(12345)\n",
    "        \n",
    "        self.conv1 = GATConv(100, 10, heads=3)\n",
    "        self.linear1 = torch.nn.Linear(10*3, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data, batch):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_geometric_graphs_glove = generate_pytorch_geometric_graphs_glove(window_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pyg_graphs_glove, test_pyg_graphs_glove = train_test_split(pytorch_geometric_graphs_glove, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gat_glove_classifier(train_batch_size=300, learning_rate=0.001, num_epoch=10):\n",
    "    train_loader = DataLoader(train_pyg_graphs_glove, batch_size=train_batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_pyg_graphs_glove, batch_size=200, shuffle=False)\n",
    "    \n",
    "    gat_model = GATGloveClassifier().to(device)\n",
    "    print(gat_model)\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    optimizer = torch.optim.Adam(gat_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    gat_model.train()\n",
    "    for epoch in range(0, num_epoch):\n",
    "        for i, data in enumerate(train_loader):  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            try:\n",
    "                out = gat_model(data, data.batch)  # Perform a single forward pass.\n",
    "            except Exception as e:\n",
    "                print(data)\n",
    "                print(data.x)\n",
    "                print(data.y)\n",
    "            out = out.squeeze()\n",
    "            y = data.y.squeeze()\n",
    "            loss = loss_function(out, y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "        print(f'Epoch: {epoch}, Epoch loss {loss.item()}')\n",
    "\n",
    "    print('Training process has finished.')\n",
    "    print('Final loss', loss.item())\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        gat_model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            out = gat_model(data, data.batch)\n",
    "            pred_labels.extend(torch.round(out.squeeze()).tolist())\n",
    "            true_labels.extend(data.y.tolist())\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, pred_labels)\n",
    "    \n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_glove_evaluation_results = []\n",
    "for num in global_random_numbers:\n",
    "    torch.manual_seed(num)\n",
    "    gat_glove_evaluation_results.append(run_gat_glove_classifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>GloVe + GATConv results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_evaluation_results(gat_glove_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove + GCNonv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNGloveClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #torch.manual_seed(12345)\n",
    "        \n",
    "        self.conv1 = GCNConv(100, 10)\n",
    "        self.linear1 = torch.nn.Linear(10, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data, batch):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gcn_glove_classifier(train_batch_size=300, learning_rate=0.001, num_epoch=10):\n",
    "    train_loader = DataLoader(train_pyg_graphs_glove, batch_size=train_batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_pyg_graphs_glove, batch_size=200, shuffle=False)\n",
    "    \n",
    "    model = GCNGloveClassifier().to(device)\n",
    "    print(model)\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(0, num_epoch):\n",
    "        for i, data in enumerate(train_loader):  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            try:\n",
    "                out = model(data, data.batch)  # Perform a single forward pass.\n",
    "            except Exception as e:\n",
    "                print(data)\n",
    "                print(data.x)\n",
    "                print(data.y)\n",
    "            out = out.squeeze()\n",
    "            y = data.y.squeeze()\n",
    "            loss = loss_function(out, y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "        print(f'Epoch: {epoch}, Epoch loss {loss.item()}')\n",
    "\n",
    "    print('Training process has finished.')\n",
    "    print('Final loss', loss.item())\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            out = model(data, data.batch)\n",
    "            pred_labels.extend(torch.round(out.squeeze()).tolist())\n",
    "            true_labels.extend(data.y.tolist())\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, pred_labels)\n",
    "    \n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_glove_evaluation_results = []\n",
    "for num in global_random_numbers:\n",
    "    torch.manual_seed(num)\n",
    "    gcn_glove_evaluation_results.append(run_gcn_glove_classifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>GloVe + GCNConv results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_evaluation_results(gcn_glove_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove + GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvGloveClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #torch.manual_seed(12345)\n",
    "        \n",
    "        self.conv1 = GraphConv(100, 10, aggr='mean')\n",
    "        self.linear1 = torch.nn.Linear(10, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data, batch):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graphconv_glove_classifier(train_batch_size=300, learning_rate=0.001, num_epoch=10):\n",
    "    train_loader = DataLoader(train_pyg_graphs_glove, batch_size=train_batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_pyg_graphs_glove, batch_size=200, shuffle=False)\n",
    "    \n",
    "    model = GraphConvGloveClassifier().to(device)\n",
    "    print(model)\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(0, num_epoch):\n",
    "        for i, data in enumerate(train_loader):  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            try:\n",
    "                out = model(data, data.batch)  # Perform a single forward pass.\n",
    "            except Exception as e:\n",
    "                print(data)\n",
    "                print(data.x)\n",
    "                print(data.y)\n",
    "            out = out.squeeze()\n",
    "            y = data.y.squeeze()\n",
    "            loss = loss_function(out, y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "        print(f'Epoch: {epoch}, Epoch loss {loss.item()}')\n",
    "\n",
    "    print('Training process has finished.')\n",
    "    print('Final loss', loss.item())\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            out = model(data, data.batch)\n",
    "            pred_labels.extend(torch.round(out.squeeze()).tolist())\n",
    "            true_labels.extend(data.y.tolist())\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, pred_labels)\n",
    "    \n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphconv_glove_evaluation_results = []\n",
    "for num in global_random_numbers:\n",
    "    torch.manual_seed(num)\n",
    "    graphconv_glove_evaluation_results.append(run_graphconv_glove_classifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>GloVe + GraphConv results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_evaluation_results(graphconv_glove_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove + SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConvGloveClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #torch.manual_seed(12345)\n",
    "        \n",
    "        self.conv1 = SAGEConv(100, 10)\n",
    "        self.linear1 = torch.nn.Linear(10, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data, batch):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sageconv_glove_classifier(train_batch_size=300, learning_rate=0.001, num_epoch=10):\n",
    "    train_loader = DataLoader(train_pyg_graphs_glove, batch_size=train_batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_pyg_graphs_glove, batch_size=200, shuffle=False)\n",
    "    \n",
    "    model = SAGEConvGloveClassifier().to(device)\n",
    "    print(model)\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(0, num_epoch):\n",
    "        for i, data in enumerate(train_loader):  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            try:\n",
    "                out = model(data, data.batch)  # Perform a single forward pass.\n",
    "            except Exception as e:\n",
    "                print(data)\n",
    "                print(data.x)\n",
    "                print(data.y)\n",
    "            out = out.squeeze()\n",
    "            y = data.y.squeeze()\n",
    "            loss = loss_function(out, y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "        print(f'Epoch: {epoch}, Epoch loss {loss.item()}')\n",
    "\n",
    "    print('Training process has finished.')\n",
    "    print('Final loss', loss.item())\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            out = model(data, data.batch)\n",
    "            pred_labels.extend(torch.round(out.squeeze()).tolist())\n",
    "            true_labels.extend(data.y.tolist())\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, pred_labels)\n",
    "    \n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sageconv_glove_evaluation_results = []\n",
    "for num in global_random_numbers:\n",
    "    torch.manual_seed(num)\n",
    "    sageconv_glove_evaluation_results.append(run_sageconv_glove_classifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>GloVe + SAGEConv results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_evaluation_results(sageconv_glove_evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pytorch_geometric_graphs_glove\n",
    "del train_pyg_graphs_glove\n",
    "del test_pyg_graphs_glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sliding_window_experiments():\n",
    "    sliding_windows = [2, 3, 4, 6, 7, 10]\n",
    "    \n",
    "    sliding_window_results = []\n",
    "    for sw in sliding_windows:\n",
    "        print('Window size:', sw)\n",
    "        pytorch_geometric_graphs = generate_pytorch_geometric_graphs(window_size=sw)\n",
    "        train_pyg_graphs, test_pyg_graphs = train_test_split(pytorch_geometric_graphs, test_size=0.33, random_state=42)\n",
    "        sliding_window_results.append((sw, run_gat_classifier(train_pyg_graphs, test_pyg_graphs)['results']))\n",
    "    return sliding_window_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sliding_window_results = run_sliding_window_experiments()\n",
    "sliding_window_results = [[sw, results[0]] for sw, results in sliding_window_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Sliding window results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = [res[0] for res in sliding_window_results]\n",
    "plot_y = [res[1] for res in sliding_window_results]\n",
    "sliding_window_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.lineplot(x=plot_x, y=plot_y)\n",
    "fig.set_xlabel('window size')\n",
    "fig.set_ylabel('accuracy')\n",
    "fig.get_figure().savefig('figures/plot_window_size.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_learning_rate_experiments():\n",
    "    learning_rates = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "    \n",
    "    learning_rate_results = []\n",
    "    for lr in learning_rates:\n",
    "        print('Learning rate:', lr)\n",
    "        #pytorch_geometric_graphs = generate_pytorch_geometric_graphs(window_size=2)\n",
    "        #train_pyg_graphs, test_pyg_graphs = train_test_split(pytorch_geometric_graphs, test_size=0.33, random_state=42)\n",
    "        learning_rate_results.append((lr, run_gat_classifier(train_pyg_graphs, test_pyg_graphs, learning_rate=lr)['results']))\n",
    "    return learning_rate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate_results = run_learning_rate_experiments()\n",
    "learning_rate_results = [[lr, results[0]] for lr, results in learning_rate_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Learning rate results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = [res[0] for res in learning_rate_results]\n",
    "plot_y = [res[1] for res in learning_rate_results]\n",
    "learning_rate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.lineplot(x=plot_x, y=plot_y)\n",
    "fig.set_xlabel('learning rate')\n",
    "fig.set_ylabel('accuracy')\n",
    "fig.get_figure().savefig('figures/plot_learning_rate.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pytorch_geometric_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_size_experiments():\n",
    "    training_sizes = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    \n",
    "    training_size_results = []\n",
    "    for ts in training_sizes:\n",
    "        print('Training size:', ts)\n",
    "        if ts == 1:\n",
    "            print('All samples')\n",
    "            tmp_graphs = pytorch_geometric_graphs\n",
    "        else:\n",
    "            tmp_graphs, _ = train_test_split(pytorch_geometric_graphs, train_size=ts, random_state=42)\n",
    "        \n",
    "        print('Number of samples:', len(tmp_graphs))\n",
    "        train_pyg_graphs, test_pyg_graphs = train_test_split(tmp_graphs, test_size=0.33, random_state=42)\n",
    "        training_size_results.append((ts, run_gat_classifier(train_pyg_graphs, test_pyg_graphs)['results']))\n",
    "    return training_size_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_size_results = run_training_size_experiments()\n",
    "training_size_results = [[ts, results[0]] for ts, results in training_size_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Dataset size results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = [res[0] for res in training_size_results]\n",
    "plot_y = [res[1] for res in training_size_results]\n",
    "training_size_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.lineplot(x=plot_x, y=plot_y)\n",
    "fig.set_xlabel('dataset size')\n",
    "fig.set_ylabel('accuracy')\n",
    "fig.get_figure().savefig('figures/training_size_rate.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw an exemplar graph-of-words graph with 15 nodes and 3 window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['body'][df['number_of_words_of_body'] == 15].values[6]\n",
    "text = text.replace(',', '')\n",
    "text = text.replace('.', '')\n",
    "g = create_graph_of_words(text, 3)\n",
    "nx.draw_kamada_kawai(g, with_labels=True, node_color='white', node_size=1300)\n",
    "plt.savefig(\"Graph1.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def run_document_visualization_experiment():\n",
    "    sw = 7\n",
    "    print('Window size:', sw)\n",
    "    pytorch_geometric_graphs = generate_pytorch_geometric_graphs(window_size=sw)\n",
    "    train_pyg_graphs, test_pyg_graphs = train_test_split(pytorch_geometric_graphs, test_size=0.33, random_state=42)\n",
    "    model = run_gat_classifier(train_pyg_graphs, test_pyg_graphs)['model']\n",
    "    \n",
    "    loader = DataLoader(pytorch_geometric_graphs, batch_size=100, shuffle=False)\n",
    "    documents_embeddings = []\n",
    "    \n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            embeddings, out = model(data, data.batch)\n",
    "            documents_embeddings.extend(embeddings.tolist())\n",
    "            pred_labels.extend(torch.round(out.squeeze()).tolist())\n",
    "    \n",
    "    print('Number of documents:', len(documents_embeddings))\n",
    "    print('Number of dimensions per document:', len(documents_embeddings[0]))\n",
    "    return documents_embeddings, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_embeddings, pred_labels = run_document_visualization_experiment()\n",
    "documents_embeddings = np.array(documents_embeddings)\n",
    "visualization_x_y = TSNE(n_components=2, learning_rate='auto', init='pca', random_state=42).fit_transform(np.array(documents_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.scatterplot(x=visualization_x_y[:, 0], y=visualization_x_y[:, 1], hue=pred_labels)\n",
    "fig.set_xlabel('')\n",
    "fig.set_ylabel('')\n",
    "fig.get_figure().savefig('figures/documents_visualization.jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents visualization fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [int(res[0].split('__label__')[1]) for res in fasttext_model.predict(df['body'].values.tolist())[0]]\n",
    "fasttext_document_embeddings = [fasttext_model.get_sentence_vector(doc) for doc in df['body'].values.tolist()]\n",
    "visualization_x_y_fasttext = TSNE(n_components=2, learning_rate='auto', init='pca', random_state=42).fit_transform(np.array(fasttext_document_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.scatterplot(x=visualization_x_y_fasttext[:, 0], y=visualization_x_y_fasttext[:, 1], hue=df['label'])\n",
    "fig.set_xlabel('')\n",
    "fig.set_ylabel('')\n",
    "fig.get_figure().savefig('figures/fasttext_real_labels_documents_visualization.jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = global_random_numbers[0]\n",
    "torch.manual_seed(num)\n",
    "result = run_gat_classifier(train_pyg_graphs, test_pyg_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_gat_conv_model = result['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fast_gat_conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gat_glove_classifier(train_batch_size=300, learning_rate=0.001, num_epoch=10):\n",
    "    train_loader = DataLoader(train_pyg_graphs_glove, batch_size=train_batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_pyg_graphs_glove, batch_size=200, shuffle=False)\n",
    "    \n",
    "    gat_model = GATGloveClassifier().to(device)\n",
    "    print(gat_model)\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    optimizer = torch.optim.Adam(gat_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    gat_model.train()\n",
    "    for epoch in range(0, num_epoch):\n",
    "        for i, data in enumerate(train_loader):  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            try:\n",
    "                out = gat_model(data, data.batch)  # Perform a single forward pass.\n",
    "            except Exception as e:\n",
    "                print(data)\n",
    "                print(data.x)\n",
    "                print(data.y)\n",
    "            out = out.squeeze()\n",
    "            y = data.y.squeeze()\n",
    "            loss = loss_function(out, y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "        print(f'Epoch: {epoch}, Epoch loss {loss.item()}')\n",
    "\n",
    "    print('Training process has finished.')\n",
    "    print('Final loss', loss.item())\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        gat_model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            out = gat_model(data, data.batch)\n",
    "            pred_labels.extend(torch.round(out.squeeze()).tolist())\n",
    "            true_labels.extend(data.y.tolist())\n",
    "    \n",
    "    results = calculate_accuracy_precision_recall(true_labels, pred_labels)\n",
    "    \n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_gat_conv_model('jfdkslj ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain th model on two sample inputs\n",
    "explainer = shap.Explainer(fasttext_model)\n",
    "shap_values = explainer([\"What a great movie! ...if you have no taste.\"])\n",
    "\n",
    "# visualize the first prediction's explanation for the POSITIVE output class\n",
    "shap.plots.text(shap_values[0, :, \"POSITIVE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...include code from https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# select a set of background examples to take an expectation over\n",
    "background = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "\n",
    "# explain predictions of the model on four images\n",
    "e = shap.DeepExplainer(model, background)\n",
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n",
    "shap_values = e.shap_values(x_test[1:5])\n",
    "\n",
    "# plot the feature attributions\n",
    "shap.image_plot(shap_values, -x_test[1:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
